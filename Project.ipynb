{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Temmy-bit/CC-Fraud-Detection/blob/main/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gflc40EnzjM8",
        "outputId": "636acf8c-eda5-43e1-90c8-cbdf604a63f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function google.colab.drive.mount>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPt8Ch3kQA4z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "# from tensorflow.keras.datasets import mnist\n",
        "import cv2 as cv\n",
        "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import ResNet50V2, ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bdzlx9huHEV6"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape, LSTM\n",
        "from keras import backend as K\n",
        "from keras.constraints import maxnorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbdX5clj46FX",
        "outputId": "2403f0bd-8f37-45e4-cfc1-52721fc338d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting extra_keras_datasets\n",
            "  Downloading extra_keras_datasets-1.2.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from extra_keras_datasets) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from extra_keras_datasets) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from extra_keras_datasets) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from extra_keras_datasets) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->extra_keras_datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->extra_keras_datasets) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->extra_keras_datasets) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->extra_keras_datasets) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->extra_keras_datasets) (1.1.0)\n",
            "Installing collected packages: extra-keras-datasets\n",
            "Successfully installed extra-keras-datasets-1.2.0\n"
          ]
        }
      ],
      "source": [
        "! pip install extra_keras_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7yV9FBs5fw8",
        "outputId": "04e957c4-b030-45d8-986d-125abce57310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Loading dataset = emnist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/matlab.zip\n",
            "743907328/743900280 [==============================] - 11s 0us/step\n",
            "743915520/743900280 [==============================] - 11s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please cite the following paper when using or referencing this Extra Keras Dataset:\n",
            "WARNING:root:Cohen, G., Afshar, S., Tapson, J., & van Schaik, A. (2017). EMNIST: an extension of MNIST to handwritten letters. Retrieved from http://arxiv.org/abs/1702.05373\n"
          ]
        }
      ],
      "source": [
        "from extra_keras_datasets import emnist\n",
        "(X_train, y_train), (X_test, y_test) = emnist.load_data(type='byclass')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KISkBB8P7oW0"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(X_train) / 255.0\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test) / 255.0\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYBmio0OQRQm",
        "outputId": "1d1cb1b4-66b0-448a-9932-27de65ec5f89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(697932, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIBQ8TlliWal",
        "outputId": "63e5eac1-999e-404c-855b-b477162e5ec3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(116323, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5lHwIMpiZzm",
        "outputId": "8d815d80-b115-470a-b509-e00519174833"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(697932,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuwKXO4xie0X"
      },
      "outputs": [],
      "source": [
        "#Reshaping all images into 28*28 for pre-processing\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZHL1OZB8Jxg"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhwtCKE_8Q5D",
        "outputId": "3492fc3a-8bed-4a64-c66e-03bf43b19d63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#Display a random image\n",
        "plt.imshow(X_train[0])\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlxGDjSJGEo8"
      },
      "outputs": [],
      "source": [
        "# #Y'all can see how an image array looks like. all float values b/w 0 and 1\n",
        "# m = X_train[2]\n",
        "# print(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eDH0HN7GJWi",
        "outputId": "17937079-0029-4ccd-a0e9-b4021792b59e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process Complete: Rotated and reversed test and train images!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "for t in range(697932):\n",
        "    X_train[t]=np.transpose(X_train[t])\n",
        "    \n",
        "#checking\n",
        "plt.imshow(X_train[0])\n",
        "plt.show\n",
        "\n",
        "#for test data  \n",
        "for t in range(116323):\n",
        "    X_test[t]=np.transpose(X_test[t])\n",
        "\n",
        "#checking\n",
        "plt.imshow(X_test[1])\n",
        "plt.show\n",
        "\n",
        "print('Process Complete: Rotated and reversed test and train images!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvrWaU3FGOgM",
        "outputId": "b67dd6ec-ae20-4f40-f567-1ce45dacc6a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#Checking the last train image, just to be sure!\n",
        "m = X_train[697931]\n",
        "plt.imshow(m)\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qgx_AU5jGTh7"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 784,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 784,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDnsJVxsGbR5",
        "outputId": "a072b634-7714-49d1-e943-3055f071b108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def resh(ipar):\n",
        "    opar = []\n",
        "    for image in ipar:\n",
        "        opar.append(image.reshape(-1))\n",
        "    return np.asarray(opar)\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "train_images = X_train.astype('float32')\n",
        "test_images = X_test.astype('float32')\n",
        "\n",
        "train_images = resh(train_images)\n",
        "test_images = resh(test_images)\n",
        "\n",
        "\n",
        "train_labels = np_utils.to_categorical(y_train, 62)\n",
        "test_labels = np_utils.to_categorical(y_test, 62)\n",
        "\n",
        "# model = keras.Sequential([\n",
        "#                         keras.layers.Flatten(input_shape=(784,28,28,1)),\n",
        "#                         keras.layers.Dense(128,activation='relu'),\n",
        "#                         keras.layers.Dense(10,activation='softmax')\n",
        "# ])\n",
        "# model.compile(optimizer = 'adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "# model.fit(train_images,train_labels,epochs =10)\n",
        "K.set_learning_phase(1)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Reshape((28,28,1), input_shape=(784,)))\n",
        "\n",
        "#add the layer below for an accuracy of 89%.(Training time - over 20 hours)\n",
        "model.add(Convolution2D(32, (5,5), input_shape=(28,28,1),activation='relu',padding='same',kernel_constraint=maxnorm(3)))\n",
        "model.add(Convolution2D(32, (5,5),activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(62, activation='softmax'))\n",
        "\n",
        "#opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
        "#opt = optimizers.Adadelta()\n",
        "opt = keras.optimizers.Adam(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSlTMkFfYS5w"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage import io\n",
        "aug = ImageDataGenerator(\n",
        "rotation_range=10,\n",
        "zoom_range=0.05,\n",
        "width_shift_range=0.1,\n",
        "height_shift_range=0.1,\n",
        "shear_range=0.15,\n",
        "horizontal_flip=False,\n",
        "fill_mode=\"nearest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKSVqqSDR0Vb",
        "outputId": "0e87da9f-fe63-44f5-afed-1b7daa3e4c36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 32)        25632     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               2359808   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 62)                31806     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,418,078\n",
            "Trainable params: 2,418,078\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "21811/21811 [==============================] - 102s 4ms/step - loss: 0.6443 - accuracy: 0.7897 - val_loss: 0.4885 - val_accuracy: 0.8307\n",
            "Epoch 2/50\n",
            "21811/21811 [==============================] - 89s 4ms/step - loss: 0.5958 - accuracy: 0.8017 - val_loss: 0.4820 - val_accuracy: 0.8334\n",
            "Epoch 3/50\n",
            "21811/21811 [==============================] - 90s 4ms/step - loss: 0.5963 - accuracy: 0.8019 - val_loss: 0.4988 - val_accuracy: 0.8282\n",
            "Epoch 4/50\n",
            "21811/21811 [==============================] - 90s 4ms/step - loss: 0.6007 - accuracy: 0.8011 - val_loss: 0.5070 - val_accuracy: 0.8247\n",
            "Epoch 5/50\n",
            "21811/21811 [==============================] - 89s 4ms/step - loss: 0.6042 - accuracy: 0.8002 - val_loss: 0.4920 - val_accuracy: 0.8273\n",
            "Epoch 6/50\n",
            "21811/21811 [==============================] - 89s 4ms/step - loss: 0.6062 - accuracy: 0.8000 - val_loss: 0.4936 - val_accuracy: 0.8281\n",
            "Epoch 7/50\n",
            "21811/21811 [==============================] - 89s 4ms/step - loss: 0.6089 - accuracy: 0.7992 - val_loss: 0.5142 - val_accuracy: 0.8256\n",
            "Epoch 8/50\n",
            "21811/21811 [==============================] - 89s 4ms/step - loss: 0.6106 - accuracy: 0.7993 - val_loss: 0.5127 - val_accuracy: 0.8238\n",
            "Epoch 9/50\n",
            "21811/21811 [==============================] - 89s 4ms/step - loss: 0.6135 - accuracy: 0.7986 - val_loss: 0.5030 - val_accuracy: 0.8250\n",
            "Epoch 10/50\n",
            "21811/21811 [==============================] - 89s 4ms/step - loss: 0.6147 - accuracy: 0.7981 - val_loss: 0.5115 - val_accuracy: 0.8233\n",
            "Epoch 11/50\n",
            "21811/21811 [==============================] - 89s 4ms/step - loss: 0.6168 - accuracy: 0.7970 - val_loss: 0.5143 - val_accuracy: 0.8248\n",
            "Epoch 12/50\n",
            "21808/21811 [============================>.] - ETA: 0s - loss: 0.6170 - accuracy: 0.7971"
          ]
        }
      ],
      "source": [
        "print(model.summary())\n",
        "history = model.fit(train_images,train_labels,validation_data=(test_images, test_labels),  epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsC1jH_zSc4W"
      },
      "outputs": [],
      "source": [
        "1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KP8u3qZ2UqUh"
      },
      "outputs": [],
      "source": [
        "#evaluating model on test data. will take time\n",
        "scores = model.evaluate(test_images,test_labels, verbose = 0)\n",
        "print(\"Accuracy: %.2f%%\"%(scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qlk9foJYUuGA"
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxNxf5WUVJhC"
      },
      "outputs": [],
      "source": [
        "objects = ('RMSDrop', 'Adam', 'Adamax', 'SGD', 'Adadelta')\n",
        "y_pos = np.arange(len(objects))\n",
        "performance = [86.2,85.39,89.53,84.29,87.11]\n",
        " \n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Optimizers')\n",
        "plt.ylim(50,100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8UXOvvfV_S6"
      },
      "outputs": [],
      "source": [
        "m = X_test[258].reshape(28,28)\n",
        "plt.imshow(m)\n",
        "plt.show\n",
        "print('prediction: '+str(model.predict(X_test[258].reshape(1,784))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9J0crERPV_Jz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "0f6c57de-8f89-44df-f22b-4436f795524b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7e1b15d20a33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "from keras.models import model_from_json\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "#saves the model info as json file\n",
        "    \n",
        "model.save_weights(\"model.h5\")\n",
        "# Creates a HDF5 file 'model.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlzjwxRAcw2i"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from keras.models import model_from_json\n",
        "\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "\n",
        "loaded_model.load_weights('model.h5')\n",
        "\n",
        "model = loaded_model\n",
        "\n",
        "\n",
        "print('Model successfully loaded')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labelNames = ['0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
        "\n",
        "from imutils import build_montages\n",
        "# initialize our list of output test images\n",
        "images = []\n",
        "# randomly select a few testing characters\n",
        "for i in np.random.choice(np.arange(0, len(testY)), size=(49,)):\n",
        "\t# classify the character\n",
        "\tprobs = model.predict(testX[np.newaxis, i])\n",
        "\tprediction = probs.argmax(axis=1)\n",
        "\tlabel = labelNames[prediction[0]]\n",
        "\t# extract the image from the test data and initialize the text\n",
        "\t# label color as green (correct)\n",
        "\timage = (testX[i] * 255).astype(\"uint8\")\n",
        "\tcolor = (0, 255, 0)\n",
        "\t# otherwise, the class label prediction is incorrect\n",
        "\tif prediction[0] != np.argmax(testY[i]):\n",
        "\t\tcolor = (0, 0, 255)\n",
        "\t# merge the channels into one image, resize the image from 32x32\n",
        "\t# to 96x96 so we can better see it and then draw the predicted\n",
        "\t# label on the image\n",
        "\timage = cv.merge([image] * 3)\n",
        "\timage = cv.resize(image, (96, 96), interpolation=cv.INTER_LINEAR)\n",
        "\tcv.putText(image, label, (5, 20), cv.FONT_HERSHEY_SIMPLEX, 0.75,\n",
        "\t\tcolor, 2)\n",
        "\t# add the image to our list of output images\n",
        "\timages.append(image)\n",
        "# construct the montage for the images\n",
        "montage = build_montages(images, (96, 96), (7, 7))[0]\n",
        "# show the output montage\n",
        "plt.imshow( montage)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HxcL_uO4-pC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flcSWfXYZ1jD"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "characters = ['0','1','2','3','4','5','6','7','8','9','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
        "\n",
        "\n",
        "#enter input image here\n",
        "image = cv2.imread('/content/drive/MyDrive/Read Books/Screenshot 2022-05-03 230342.png')\n",
        "height, width, depth = image.shape\n",
        "\n",
        "#resizing the image to find spaces better\n",
        "image = cv2.resize(image, dsize=(width*5,height*4), interpolation=cv2.INTER_CUBIC)\n",
        "#grayscale\n",
        "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "#binary\n",
        "ret,thresh = cv2.threshold(gray,127,255,cv2.THRESH_BINARY_INV)\n",
        "\n",
        "\n",
        "#dilation\n",
        "kernel = np.ones((5,5), np.uint8)\n",
        "img_dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
        "\n",
        "\n",
        "#adding GaussianBlur\n",
        "gsblur=cv2.GaussianBlur(img_dilation,(5,5),0)\n",
        "\n",
        "\n",
        "#find contours\n",
        "ctrs,hier = cv2.findContours(gsblur.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IqTgYorA9Rq"
      },
      "outputs": [],
      "source": [
        "\t# re-grab the image dimensions (now that its been resized)\n",
        "# and then determine how much we need to pad the width and\n",
        "# height such that our image will be 32x32\n",
        "(tH, tW) = thresh.shape\n",
        "dX = int(max(0, 32 - tW) / 2.0)\n",
        "dY = int(max(0, 32 - tH) / 2.0)\n",
        "# pad the image and force 32x32 dimensions\n",
        "padded = cv2.copyMakeBorder(thresh, top=dY, bottom=dY,\n",
        "  left=dX, right=dX, borderType=cv2.BORDER_CONSTANT,\n",
        "  value=(0, 0, 0))\n",
        "padded = cv2.resize(padded, (32, 32))\n",
        "# prepare the padded image for classification via our\n",
        "# handwriting OCR model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fOFXBnNpSum"
      },
      "outputs": [],
      "source": [
        "# max_width = max(ctrs, key=lambda r: r[0] + r[2])[0]\n",
        "# max_height = max(ctrs, key=lambda r: r[3])[3]\n",
        "# nearest = max_height * 1.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FE9WmgBKeAh"
      },
      "outputs": [],
      "source": [
        "# count = np.unique(ctrs, return_counts=True)[1]\n",
        "# np.repeat(ctrs, count[np.argsort(ctrs)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X63qaMFlI0P3"
      },
      "outputs": [],
      "source": [
        "# c = ctrs\n",
        "# np.repeat(lambda r: (int(nearest * round(float(r[1])/nearest)) * max_width + r[0])), [c[v] for v in r]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9ub2hmUHa_B"
      },
      "outputs": [],
      "source": [
        "# np.repeat(ctrs,np.bincount(ctrs)[ r: (int(nearest * round(float(r[1])/nearest)) * max_width + r[0])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIyoLJ1UGpW_"
      },
      "outputs": [],
      "source": [
        "may = (int(nearest * round(float(r[1])/nearest)) * max_width + r[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsWZF0laCVpQ"
      },
      "outputs": [],
      "source": [
        "ctrs.sort(ctrs,key=lambda r: (int(nearest * round(float(r[1])/nearest)) * max_width + r[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWPAp2ruok51"
      },
      "outputs": [],
      "source": [
        "m = list()\n",
        "#sort contours\n",
        "sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
        "pchl = list()\n",
        "dp = image.copy()\n",
        "for i, ctr in enumerate(sorted_ctrs):\n",
        "    # Get bounding box\n",
        "    x, y, w, h = cv2.boundingRect(ctr)\n",
        "    cv2.rectangle(dp,(x-10,y-10),( x + w + 10, y + h + 10 ),(90,0,255),9)\n",
        "    \n",
        "plt.imshow(dp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKcKwGt2gBU0"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread()\n",
        "height, width, depth = image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf_KRfDkgGOS"
      },
      "outputs": [],
      "source": [
        "plt.imshow(image),image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x366vMOseohi"
      },
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3YviJTiXdYH"
      },
      "outputs": [],
      "source": [
        "x = X_train[11280][0:]\n",
        "x = x.reshape((28, 28))\n",
        "plt.imshow(x, cmap='gist_yarg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGSpCjy49qin"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 784,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 784,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM3-gmV0YBeW"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imutils"
      ],
      "metadata": {
        "id": "6HSQenoaWHk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uvl9DPEy8rpc"
      },
      "outputs": [],
      "source": [
        "# load the input image from disk, convert it to grayscale, and blur\n",
        "# it to reduce noise\n",
        "image = cv2.imread('/content/drive/MyDrive/1581999808182.jpg')\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "# perform edge detection, find contours in the edge map, and sort the\n",
        "# resulting contours from left-to-right\n",
        "edged = cv2.Canny(blurred, 30, 150)\n",
        "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
        "\tcv2.CHAIN_APPROX_SIMPLE)\n",
        "cnts = imutils.grab_contours(cnts)\n",
        "cnts = sorted_ctrs(cnts, method=\"left-to-right\")[0]\n",
        "# initialize the list of contour bounding boxes and associated\n",
        "# characters that we'll be OCR'ing\n",
        "chars = []\n",
        "# loop over the contours\n",
        "for c in cnts:\n",
        "\t# compute the bounding box of the contour\n",
        "\t(x, y, w, h) = cv2.boundingRect(c)\n",
        "\t# filter out bounding boxes, ensuring they are neither too small\n",
        "\t# nor too large\n",
        "\tif (w >= 5 and w <= 150) and (h >= 15 and h <= 120):\n",
        "\t\t# extract the character and threshold it to make the character\n",
        "\t\t# appear as *white* (foreground) on a *black* background, then\n",
        "\t\t# grab the width and height of the thresholded image\n",
        "\t\troi = gray[y:y + h, x:x + w]\n",
        "\t\tthresh = cv2.threshold(roi, 0, 255,\n",
        "\t\t\tcv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "\t\t(tH, tW) = thresh.shape\n",
        "\t\t# if the width is greater than the height, resize along the\n",
        "\t\t# width dimension\n",
        "\t\tif tW > tH:\n",
        "\t\t\tthresh = imutils.resize(thresh, width=32)\n",
        "\t\t# otherwise, resize along the height\n",
        "\t\telse:\n",
        "\t\t\tthresh = imutils.resize(thresh, height=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXqDA30nyYHI"
      },
      "outputs": [],
      "source": [
        "# re-grab the image dimensions (now that its been resized)\n",
        "\t\t# and then determine how much we need to pad the width and\n",
        "\t\t# height such that our image will be 32x32\n",
        "\t\t(tH, tW) = thresh.shape\n",
        "\t\tdX = int(max(0, 32 - tW) / 2.0)\n",
        "\t\tdY = int(max(0, 32 - tH) / 2.0)\n",
        "\t\t# pad the image and force 32x32 dimensions\n",
        "\t\tpadded = cv2.copyMakeBorder(thresh, top=dY, bottom=dY,\n",
        "\t\t\tleft=dX, right=dX, borderType=cv2.BORDER_CONSTANT,\n",
        "\t\t\tvalue=(0, 0, 0))\n",
        "\t\tpadded = cv2.resize(padded, (32, 32))\n",
        "\t\t# prepare the padded image for classification via our\n",
        "\t\t# handwriting OCR model\n",
        "\t\tpadded = padded.astype(\"float32\") / 255.0\n",
        "\t\tpadded = np.expand_dims(padded, axis=-1)\n",
        "\t\t# update our list of characters that will be OCR'd\n",
        "\t\tchars.append((padded, (x, y, w, h)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8Xd_Zehylg7"
      },
      "outputs": [],
      "source": [
        "# extract the bounding box locations and padded characters\n",
        "boxes = [b[1] for b in chars]\n",
        "chars = np.array([c[0] for c in chars], dtype=\"float32\")\n",
        "# OCR the characters using our handwriting recognition model\n",
        "preds = model.predict(chars)\n",
        "# define the list of label names\n",
        "labelNames = \"0123456789\"\n",
        "labelNames += \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "labelNames = [l for l in labelNames]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVQhUtqfzB7d"
      },
      "outputs": [],
      "source": [
        "# loop over the predictions and bounding box locations together\n",
        "for (pred, (x, y, w, h)) in zip(preds, boxes):\n",
        "\t# find the index of the label with the largest corresponding\n",
        "\t# probability, then extract the probability and label\n",
        "\ti = np.argmax(pred)\n",
        "\tprob = pred[i]\n",
        "\tlabel = labelNames[i]\n",
        "\t# draw the prediction on the image\n",
        "\tprint(\"[INFO] {} - {:.2f}%\".format(label, prob * 100))\n",
        "\tcv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\tcv2.putText(image, label, (x - 10, y - 10),\n",
        "\t\tcv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
        "\t# show the image\n",
        "\tcv2.imshow(\"Image\", image)\n",
        "\tcv2.waitKey(0)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Project.ipynb",
      "provenance": [],
      "mount_file_id": "1buodfLTQ_pPIY8bK5_6Tzc4ljlJ8_76T",
      "authorship_tag": "ABX9TyNQphHpBMYi6lrmz6oPQBZN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}